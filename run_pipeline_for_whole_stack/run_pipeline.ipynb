{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "- numpy\n",
    "- scikit-learn\n",
    "- pytorch\n",
    "- torchvision\n",
    "- opencv-python\n",
    "- h5py\n",
    "- tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./SAM\")\n",
    "sys.path.append(\"./utils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image, ImageSequence\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "import SAM\n",
    "from SAM.models import LightHQSAM\n",
    "from utils.data import (\n",
    "    get_stack_sizes,\n",
    "    get_num_target_patches\n",
    ")\n",
    "from utils.extract import (\n",
    "    get_patch_sizes,\n",
    "    get_sam_embeddings_for_slice\n",
    ")\n",
    "from utils.postprocess import postprocess_segmentation\n",
    "from utils.postprocess_with_sam import postprocess_segmentations_with_sam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Input, RF Model and the result directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image\n",
    "data_path = \"../data/Stack02_819_3598_cor_TM1corb_cr/Substack.tif\"\n",
    "data_path = Path(data_path)\n",
    "print(f\"data_path exists: {data_path.exists()}\")\n",
    "\n",
    "# random forest model\n",
    "rf_model_path = \"../data/Stack02_819_3598_cor_TM1corb_cr/rf_model_1.bin\"\n",
    "rf_model_path = Path(rf_model_path)\n",
    "print(f\"rf_model_path exists: {rf_model_path.exists()}\")\n",
    "\n",
    "# result folder\n",
    "segmentation_dir = data_path.joinpath(\"segmentation_results\")\n",
    "segmentation_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# temporary storage path for saving extracted embeddings patches\n",
    "storage_path = \"./temp_storage.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the SAM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"running on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sam model (light hq sam)\n",
    "sam_model = LightHQSAM.setup().to(device)\n",
    "# load weights\n",
    "weights = torch.load(\n",
    "    \"./SAM/models/weights/sam_hq_vit_tiny.pth\",\n",
    "    map_location=device\n",
    ")\n",
    "sam_model.load_state_dict(weights, strict=True)\n",
    "sam_model.eval()\n",
    "\n",
    "sam_encoder = sam_model.image_encoder\n",
    "\n",
    "print(sam_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_slice(rf_model, patch_dataset, img_height, img_width, patch_size, target_patch_size):\n",
    "    \"\"\"Predict a slice patch by patch\"\"\"\n",
    "    segmentation_image = []\n",
    "    # shape: N x target_size x target_size x C\n",
    "    feature_patches = patch_dataset[:]\n",
    "    num_patches = feature_patches.shape[0]\n",
    "    total_channels = SAM.ENCODER_OUT_CHANNELS + SAM.EMBED_PATCH_CHANNELS\n",
    "\n",
    "    for i in tqdm(\n",
    "        range(num_patches), desc=\"Predicting slice patches\", position=1, leave=True\n",
    "    ):\n",
    "        input_data = feature_patches[i].reshape(-1, total_channels)\n",
    "        predictions = rf_model.predict(input_data).astype(np.uint8)\n",
    "        segmentation_image.append(predictions)\n",
    "\n",
    "    segmentation_image = np.vstack(segmentation_image)\n",
    "    # reshape into the image size + padding\n",
    "    patch_rows, patch_cols = get_num_target_patches(\n",
    "        img_height, img_width, patch_size, target_patch_size\n",
    "    )\n",
    "    segmentation_image = segmentation_image.reshape(\n",
    "        patch_rows, patch_cols, target_patch_size, target_patch_size\n",
    "    )\n",
    "    segmentation_image = np.moveaxis(segmentation_image, 1, 2).reshape(\n",
    "        patch_rows * target_patch_size,\n",
    "        patch_cols * target_patch_size\n",
    "    )\n",
    "    # skip paddings\n",
    "    segmentation_image = segmentation_image[:img_height, :img_width]\n",
    "\n",
    "    return segmentation_image\n",
    "\n",
    "\n",
    "def postprocess(segmentation_image, area_threshold, use_sam=False, sam_model=None):\n",
    "    area_threshold = area_threshold / 100\n",
    "    if use_sam:\n",
    "        post_image = postprocess_segmentations_with_sam(\n",
    "            sam_model, segmentation_image, area_threshold\n",
    "        )\n",
    "    else:\n",
    "        post_image = postprocess_segmentation(\n",
    "            segmentation_image, area_threshold\n",
    "        )\n",
    "\n",
    "    return post_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Input and Temporary Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get patch sizes\n",
    "input_stack = Image.open(data_path)\n",
    "\n",
    "num_slices = input_stack.n_frames\n",
    "img_height = input_stack.height\n",
    "img_width = input_stack.width\n",
    "\n",
    "patch_size, target_patch_size = get_patch_sizes(img_height, img_width)\n",
    "\n",
    "print(num_slices, img_height, img_width)\n",
    "print(patch_size, target_patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(rf_model_path, mode=\"rb\") as f:\n",
    "    rf_model = pickle.load(f)\n",
    "    rf_model.set_params(verbose=0)\n",
    "\n",
    "rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = h5py.File(storage_path, \"w\")\n",
    "storage_group = storage.create_group(\"slice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post-processing parameters\n",
    "do_postprocess = True\n",
    "post_use_sam = False\n",
    "area_threshold = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_img = Image.open(data_path)\n",
    "for i, page in tqdm(\n",
    "    enumerate(ImageSequence.Iterator(tiff_img)),\n",
    "    desc=\"Slices\", total=num_slices, position=0\n",
    "):\n",
    "    # print(f\"slice {i + 1}\", end=\"\\n\")\n",
    "    slice_img = np.array(page.convert(\"L\"))\n",
    "\n",
    "    get_sam_embeddings_for_slice(\n",
    "        slice_img, patch_size, target_patch_size,\n",
    "        sam_encoder, device, storage_group\n",
    "    )\n",
    "\n",
    "    segmentation_image = predict_slice(\n",
    "        rf_model, storage_group[\"sam\"],\n",
    "        img_height, img_width,\n",
    "        patch_size, target_patch_size\n",
    "    )\n",
    "\n",
    "    if do_postprocess:\n",
    "        segmentation_image = postprocess(\n",
    "            segmentation_image, area_threshold,\n",
    "            post_use_sam, sam_model\n",
    "        )\n",
    "\n",
    "    # save result\n",
    "    img = Image.fromarray(segmentation_image)\n",
    "    img.save(segmentation_dir.joinpath(f\"slice_{i}.tiff\"))\n",
    "\n",
    "\n",
    "if storage is not None:\n",
    "    storage.close()\n",
    "Path(storage_path).unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if storage is not None:\n",
    "    storage.close()\n",
    "Path(storage_path).unlink()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project52",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
